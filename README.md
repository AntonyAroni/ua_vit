# Vision Transformer (ViT) for Fashion-MNIST

Un Vision Transformer implementado desde cero en C++ con CUDA para clasificaciÃ³n de imÃ¡genes Fashion-MNIST.

## ğŸ“‹ DescripciÃ³n

Este proyecto implementa un Vision Transformer (ViT) completamente funcional usando C++ y CUDA para acelerar el entrenamiento en GPU. El modelo estÃ¡ diseÃ±ado para clasificar imÃ¡genes del dataset Fashion-MNIST (10 clases de ropa).

### CaracterÃ­sticas principales:
- **ImplementaciÃ³n desde cero**: Vision Transformer completo sin dependencias de frameworks de ML
- **AceleraciÃ³n GPU**: Operaciones matriciales optimizadas con cuBLAS
- **Arquitectura modular**: CÃ³digo organizado en clases reutilizables
- **Entrenamiento completo**: Forward pass, backward pass y optimizaciÃ³n Adam
- **MÃ©tricas en tiempo real**: Loss y accuracy durante el entrenamiento

## ğŸ—ï¸ Arquitectura del Modelo

- **Patch Size**: 4x4 pÃ­xeles
- **Embedding Dimension**: 128
- **Transformer Depth**: 2 capas
- **Attention Heads**: 4
- **MLP Hidden Dimension**: 256 (2x embedding dim)
- **Batch Size**: 64
- **Learning Rate**: 3e-3 con cosine annealing

## ğŸ› ï¸ Requisitos del Sistema

### Hardware
- GPU NVIDIA con compute capability 3.5+
- MÃ­nimo 4GB de VRAM
- 8GB+ de RAM del sistema

### Software
- **CUDA Toolkit 11.0+** (probado con 12.6)
- **CMake 3.18+**
- **GCC 9.0+** o compilador compatible con C++17
- **cuBLAS** (incluido con CUDA Toolkit)

### Verificar instalaciÃ³n CUDA:
```bash
nvcc --version
nvidia-smi
```

## ğŸ“¦ InstalaciÃ³n y ConfiguraciÃ³n

### 1. Clonar el repositorio
```bash
git clone <repository-url>
cd ia_vit
```

### 2. Configurar CUDA (si es necesario)
```bash
chmod +x setup_cuda.sh
./setup_cuda.sh
```

### 3. Descargar el dataset Fashion-MNIST
```bash
mkdir -p data
cd data

# Descargar archivos
wget http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz
wget http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz
wget http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz
wget http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz

# Descomprimir
gunzip *.gz
cd ..
```

### 4. Compilar el proyecto
```bash
mkdir -p build
cd build

# Configurar con CMake
cmake .. -DCMAKE_CUDA_COMPILER=/usr/local/cuda/bin/nvcc -DCMAKE_CUDA_ARCHITECTURES=75

# Compilar
make -j$(nproc)
```

**Nota**: Ajusta `CMAKE_CUDA_ARCHITECTURES` segÃºn tu GPU:
- GTX 1650/1660: `75`
- RTX 20xx: `75`
- RTX 30xx: `86`
- RTX 40xx: `89`

## ğŸš€ EjecuciÃ³n

### Entrenar el modelo
```bash
cd build
./ia_vit
```

### Salida esperada
```
=== Vision Transformer for Fashion-MNIST ===
Initializing CUDA...
Using GPU: NVIDIA GeForce GTX 1650
Memory: 4096 MB
Compute Capability: 7.5

=== Model Configuration ===
Batch size: 64
Epochs: 50
Learning rate: 0.003
Image size: 28x28
Patch size: 4x4
Embedding dimension: 128
Transformer depth: 2
Number of heads: 4

=== Loading Fashion-MNIST Dataset ===
Training samples: 60000
Test samples: 10000

=== Starting Training ===
Epoch   1/50 | Time: 2.6s
Train Loss: 2.1378 | Train Acc: 28.31%
Val Acc: 37.40%
Learning Rate: 2.87e-03
```

## ğŸ“Š Rendimiento Esperado

### MÃ©tricas de entrenamiento tÃ­picas:
- **Ã‰poca 1**: Loss ~2.13, Accuracy ~28%
- **Ã‰poca 10**: Loss ~2.05, Accuracy ~35%
- **Ã‰poca 20**: Loss ~1.85, Accuracy ~42%
- **Ã‰poca 50**: Loss ~1.45, Accuracy ~48%

### Tiempo de entrenamiento:
- **GTX 1650**: ~2.6s por Ã©poca
- **RTX 3070**: ~1.2s por Ã©poca
- **RTX 4090**: ~0.8s por Ã©poca

## ğŸ—‚ï¸ Estructura del Proyecto

```
ia_vit/
â”œâ”€â”€ main.cpp                 # Punto de entrada y loop de entrenamiento
â”œâ”€â”€ vit_transformer.h/cpp    # ImplementaciÃ³n del Vision Transformer
â”œâ”€â”€ data_loader.h/cpp        # Cargador del dataset Fashion-MNIST
â”œâ”€â”€ cuda_kernels.cu          # Kernels CUDA personalizados
â”œâ”€â”€ regularization.h         # TÃ©cnicas de regularizaciÃ³n
â”œâ”€â”€ CMakeLists.txt          # ConfiguraciÃ³n de compilaciÃ³n
â”œâ”€â”€ setup_cuda.sh          # Script de configuraciÃ³n CUDA
â”œâ”€â”€ data/                   # Dataset Fashion-MNIST
â”‚   â”œâ”€â”€ train-images-idx3-ubyte
â”‚   â”œâ”€â”€ train-labels-idx1-ubyte
â”‚   â”œâ”€â”€ t10k-images-idx3-ubyte
â”‚   â””â”€â”€ t10k-labels-idx1-ubyte
â””â”€â”€ build/                  # Archivos compilados
    â””â”€â”€ ia_vit             # Ejecutable
```

## ğŸ”§ PersonalizaciÃ³n

### Modificar hiperparÃ¡metros
Edita las constantes en `main.cpp`:
```cpp
const int batch_size = 64;
const int epochs = 50;
const float initial_lr = 3e-3f;
const int embed_dim = 128;
const int depth = 2;
const int num_heads = 4;
```

### Cambiar arquitectura
Modifica la clase `VisionTransformer` en `vit_transformer.h/cpp` para:
- Agregar mÃ¡s capas transformer
- Cambiar dimensiones de embedding
- Implementar diferentes tipos de atenciÃ³n

## ğŸ› SoluciÃ³n de Problemas

### Error: "No CUDA devices found"
```bash
# Verificar drivers NVIDIA
nvidia-smi

# Reinstalar CUDA Toolkit
sudo apt update
sudo apt install nvidia-cuda-toolkit
```

### Error: "CMAKE_CUDA_COMPILER could not be found"
```bash
# Encontrar nvcc
which nvcc
# Usar la ruta completa en cmake
cmake .. -DCMAKE_CUDA_COMPILER=/usr/local/cuda/bin/nvcc
```

### Error: "Failed to load data"
```bash
# Verificar que el dataset estÃ© en la ubicaciÃ³n correcta
ls -la data/
# Debe mostrar los 4 archivos .ubyte
```

### Memoria GPU insuficiente
- Reducir `batch_size` en `main.cpp`
- Reducir `embed_dim` o `depth`

## ğŸ“ˆ Mejoras Futuras

- [ ] Implementar data augmentation
- [ ] Agregar soporte para mÃºltiples GPUs
- [ ] Optimizar kernels CUDA personalizados
- [ ] Implementar diferentes schedulers de learning rate
- [ ] Agregar tÃ©cnicas de regularizaciÃ³n avanzadas
- [ ] Soporte para otros datasets (CIFAR-10, ImageNet)

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la licencia MIT. Ver `LICENSE` para mÃ¡s detalles.

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Por favor:
1. Fork el proyecto
2. Crea una rama para tu feature
3. Commit tus cambios
4. Push a la rama
5. Abre un Pull Request

## ğŸ“ Soporte

Si encuentras problemas o tienes preguntas:
- Abre un issue en GitHub
- Revisa la secciÃ³n de soluciÃ³n de problemas
- Verifica que tu sistema cumple los requisitos

---

**Desarrollado usando C++ y CUDA**